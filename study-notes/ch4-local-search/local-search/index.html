<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Study notes on Artificial Intelligence book by Russell and Norvig."><meta name=author content=RoundofThree><link href=https://roundofthree.github.io/AIMA-notes/en/study-notes/ch4-local-search/local-search/ rel=canonical><link rel=icon href=https://roundofthree.github.io/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-7.1.3"><title>Non-Classical Search - AIMA notes</title><link rel=stylesheet href=../../../assets/stylesheets/main.e35208c4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ef6f36e2.min.css><meta name=theme-color content=#02a6f2><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Noto+Sans:300,400,400i,700%7CSource+Code+Pro&display=fallback"><style>:root{--md-text-font-family:"Noto Sans";--md-code-font-family:"Source Code Pro"}</style></head> <body dir=ltr data-md-color-scheme=preference data-md-color-primary=light-blue data-md-color-accent=red> <script>function __prefix(e){return new URL("../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#non-classical-search class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AIMA notes" class="md-header__button md-logo" aria-label="AIMA notes" data-md-component=logo> <img src=https://roundofthree.github.io/favicon.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AIMA notes </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Non-Classical Search </span> </div> </div> </div> <div class=md-header__option> <div class=md-select> <button class="md-header__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24z"/></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a href=/ hreflang class=md-select__link> en - English </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/RoundofThree/AIMA-notes/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </div> <div class=md-source__repository> RoundofThree/AIMA-notes </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Start </a> </li> <li class=md-tabs__item> <a href=../../ch2-intelligent-agents/intelligent-agents/ class="md-tabs__link md-tabs__link--active"> Study Notes </a> </li> <li class=md-tabs__item> <a href=../../../exercises/tutorial-1/tutorial-1/ class=md-tabs__link> Exercises </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AIMA notes" class="md-nav__button md-logo" aria-label="AIMA notes" data-md-component=logo> <img src=https://roundofthree.github.io/favicon.png alt=logo> </a> AIMA notes </label> <div class=md-nav__source> <a href=https://github.com/RoundofThree/AIMA-notes/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </div> <div class=md-source__repository> RoundofThree/AIMA-notes </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1 type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1> Start <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Start data-md-level=1> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Start </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> Introduction </a> </li> <li class=md-nav__item> <a href=../../../discussion/ class=md-nav__link> Discussion </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2> Study Notes <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Study Notes" data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Study Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ch2-intelligent-agents/intelligent-agents/ class=md-nav__link> Intelligent agents </a> </li> <li class=md-nav__item> <a href=../../ch3-classical-search/classical-search/ class=md-nav__link> Classical Search </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Non-Classical Search <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Non-Classical Search </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#deterministic-discrete-environments class=md-nav__link> Deterministic discrete environments </a> </li> <li class=md-nav__item> <a href=#deterministic-continuous-environments class=md-nav__link> Deterministic continuous environments </a> </li> <li class=md-nav__item> <a href=#non-deterministic-environments class=md-nav__link> Non-deterministic environments </a> </li> <li class=md-nav__item> <a href=#partially-observable-environments class=md-nav__link> Partially observable environments </a> <nav class=md-nav aria-label="Partially observable environments"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sensorless-problems class=md-nav__link> Sensorless problems </a> <nav class=md-nav aria-label="Sensorless problems"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#incremental-belief-state-search class=md-nav__link> Incremental belief state search </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#with-observation class=md-nav__link> With observation </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#unknown-environments class=md-nav__link> Unknown environments </a> <nav class=md-nav aria-label="Unknown environments"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#online-depth-first-search-agent class=md-nav__link> Online Depth first search agent </a> </li> <li class=md-nav__item> <a href=#learning-real-time-a-agent-lrta class=md-nav__link> Learning real-time A agent (LRTA) </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../ch5-adversarial-search/adversarial-search/ class=md-nav__link> Adversarial search </a> </li> <li class=md-nav__item> <a href=../../ch6-csp/csp/ class=md-nav__link> Constraint Satisfaction problems </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> Exercises <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Exercises data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Exercises </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../exercises/tutorial-1/tutorial-1/ class=md-nav__link> Tutorial 1 ─ Classical search and adversarial search </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-2/tutorial-2/ class=md-nav__link> Tutorial 2 ─ Constraint Satisfaction Problems </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-3/tutorial-3/ class=md-nav__link> Tutorial 3 ─ Classical Planning </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-4/tutorial-4/ class=md-nav__link> Tutorial 4 ─ Relaxed Planning Graph Planning </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-5/tutorial-5/ class=md-nav__link> Tutorial 5 ─ AI under Uncertainty (MDP) </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-6/tutorial-6/ class=md-nav__link> Tutorial 6 ─ Unsupervised learning </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-7/tutorial-7/ class=md-nav__link> Tutorial 7 ─ Supervised learning </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-8/tutorial-8/ class=md-nav__link> Tutorial 8 ─ Reinforcement learning </a> </li> <li class=md-nav__item> <a href=../../../exercises/tutorial-9/tutorial-9/ class=md-nav__link> Revision questions </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#deterministic-discrete-environments class=md-nav__link> Deterministic discrete environments </a> </li> <li class=md-nav__item> <a href=#deterministic-continuous-environments class=md-nav__link> Deterministic continuous environments </a> </li> <li class=md-nav__item> <a href=#non-deterministic-environments class=md-nav__link> Non-deterministic environments </a> </li> <li class=md-nav__item> <a href=#partially-observable-environments class=md-nav__link> Partially observable environments </a> <nav class=md-nav aria-label="Partially observable environments"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sensorless-problems class=md-nav__link> Sensorless problems </a> <nav class=md-nav aria-label="Sensorless problems"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#incremental-belief-state-search class=md-nav__link> Incremental belief state search </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#with-observation class=md-nav__link> With observation </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#unknown-environments class=md-nav__link> Unknown environments </a> <nav class=md-nav aria-label="Unknown environments"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#online-depth-first-search-agent class=md-nav__link> Online Depth first search agent </a> </li> <li class=md-nav__item> <a href=#learning-real-time-a-agent-lrta class=md-nav__link> Learning real-time A agent (LRTA) </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/RoundofThree/AIMA-notes/blob/master/docs/en/docs/study-notes/ch4-local-search/local-search.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=non-classical-search>Non-Classical Search<a class=headerlink href=#non-classical-search title="Permanent link">&para;</a></h1> <p>These algorithms are designed for task environments other than finding the shortest path to a goal in a fully-observable, deterministic and discrete environment (that classical search assumes). It is also called <strong>local search</strong>. The path to the goal is not important. The aim is to find find the best state according to an <strong>objective function</strong> (<strong>optimization</strong>).</p> <p>Properties: - Completeness: always find a goal if it exists - Optimality: always find the global minimum/maximum</p> <h2 id=deterministic-discrete-environments>Deterministic discrete environments<a class=headerlink href=#deterministic-discrete-environments title="Permanent link">&para;</a></h2> <ul> <li>Steepest ascent hill climbing / greedy local search<ul> <li>Choose the best successor</li> <li>Completeness: no</li> <li>Does not maintain a search tree in memory</li> <li>Can get stuck for: local maxima, ridges, plateaux (which may be a shoulder)</li> <li>Variation: allow sideways moves, limiting the number of consecutive sideways moves</li> </ul> </li> <li>Stochastic hill climbing<ul> <li>Choose a random successor from successors whose <code>f(s)</code> is better</li> <li>Completeness: no</li> <li>Slower convergence</li> </ul> </li> <li>First choice hill climbing<ul> <li>Choose the first generated successor whose <code>f(s)</code> is better</li> <li>Suitable for when a state has many successors</li> <li>Completeness: no</li> </ul> </li> <li>Random restart hill climbing<ul> <li>Randomly generate initial states, run hill climbing, repeat until a goal is found</li> <li>Completeness: yes</li> <li>Expected number of restarts: <code>1/p</code> if each hill climbing has <code>p</code> probability of success</li> </ul> </li> <li>Simulated annealing <ul> <li>Choose a random move:<ul> <li>If the successor has better <code>f(s)</code>, current = successor</li> <li>Otherwise, accept with probability <code>P = T / \delta{E}</code>, where <code>T = temperature</code> </li> </ul> </li> <li>Decrease the <code>T</code></li> <li>VLSI layout problem, large scale optimizations...</li> </ul> </li> <li>Local beam search<ul> <li>Start with k random states, select the best k successors in the set of all successors and repeat until a goal is found</li> <li>Different to random restart hill climbing in that information is shared along all instances, but this can cause concentration in one instance (lack of diversity)</li> </ul> </li> <li>Stochastic local beam search<ul> <li>Choose k successors at random, with <code>P(s)</code> proportional to <code>f(s)</code></li> <li>Increase diversity to local beam search </li> </ul> </li> <li>Genetic algorithm -&gt; mutation and crossover<ul> <li><strong>Population</strong> contains random k initial <strong>individuals</strong>, represented as bitstrings</li> <li>Choose parents, the <code>P</code> of being chosen is proportional to <strong>fitness function</strong></li> <li><strong>Crossover</strong>: there are different crossover operations, eg. split point</li> <li><strong>Mutation</strong>: small probability, eg <code>1/m</code>, where <code>m = len(bitstring)</code></li> </ul> </li> </ul> <h2 id=deterministic-continuous-environments>Deterministic continuous environments<a class=headerlink href=#deterministic-continuous-environments title="Permanent link">&para;</a></h2> <p>We can discretize the search space with a fixed <code>\delta</code>. Stochastic hill climbing and simulated annealing don't need to discretize for they choose successors randomly with <code>\delta</code> vector magnitude. </p> <p><strong>Gradient</strong> (for multivariate problem, the gradient is only local): <div class=highlight><pre><span></span><code>\nabla f = (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \frac{\partial f}{\partial x_3})
</code></pre></div> <strong>Empirical gradient</strong>: for non differentiable functions, interact with the environment. </p> <p>Each step update, where <code>x</code> is a vector: <div class=highlight><pre><span></span><code>x &lt;- x + \alpha * \nabla f(x)
</code></pre></div> <code>\alpha</code> is a small constant, which can be adjusted during the search. For example, <strong>linear search</strong> doubles <code>\alpha</code> until <code>f</code> starts to decrease. </p> <ul> <li>Newton Raphson method </li> </ul> <p>In univariate calculus, <div class=highlight><pre><span></span><code>x &lt;- x - g(x) / g&#39;(x)
</code></pre></div></p> <p>In matrix-vector form in multivariate calculus, <div class=highlight><pre><span></span><code>x &lt;- x - H_{f}^{-1}(x) * \nabla f(x)
</code></pre></div></p> <p><code>H_f</code> is the Hessian matrix: <div class=highlight><pre><span></span><code>H_{i, j} = \frac{\partial^2 f}{\partial x_i \partial x_j}
</code></pre></div></p> <ul> <li>Linear programming and Convex optimisation</li> </ul> <h2 id=non-deterministic-environments>Non-deterministic environments<a class=headerlink href=#non-deterministic-environments title="Permanent link">&para;</a></h2> <p>For non-deterministic or partially observable environments, the <strong>percepts</strong> become very important. </p> <p><strong>Non-deterministic transition model</strong>: returns a set of possible outcomes <br> <strong>Contingent solution</strong>: tree of if-then-else statements <br> <strong>OR node</strong>: the agent chooses the action to perform. Input is a state. <br> <strong>AND node</strong>: the environment chooses the outcome. Input is a set of states. <br> <strong>Cyclic solution</strong>: a possible solution may be to try an action repeatedly until eventually reaching the goal.</p> <p>Algorithms: </p> <ul> <li>Recursive DFS AND-OR graph search<ul> <li>To avoid cycles, return failure if the current state is a state on the path from the root.</li> </ul> </li> <li>BFS or Best first search, A* and so... AND-OR graph search</li> </ul> <h2 id=partially-observable-environments>Partially observable environments<a class=headerlink href=#partially-observable-environments title="Permanent link">&para;</a></h2> <p><strong>Belief state</strong>: possible physical states the agent may be in</p> <h3 id=sensorless-problems>Sensorless problems<a class=headerlink href=#sensorless-problems title="Permanent link">&para;</a></h3> <p>The state space consists of belief states instead of physical states. In this space, the problem is fully observable. Therefore, the solution is not a contingent one, but a sequence of actions. </p> <p>Problem definition: - Belief states: <code>2^n</code>, where n is the number of physical states - Initial state: usually set of all states in P - Actions: union of all actions (if illegal actions have no effect) or intersection of all (safer) actions - Transition model: <code>b' = {s' : s' = result(s, a) and s in b}</code> - Goal: all s in <code>b</code> belief state satisfy the goal test - Path cost: assume same for all actions for simplicity</p> <p>Pruning: if a belief state is solvable, its superset and subset is guaranteed to be solvable. </p> <p>Algorithms: - All search algorithms applied to the problem expressed in belief state space </p> <h4 id=incremental-belief-state-search>Incremental belief state search<a class=headerlink href=#incremental-belief-state-search title="Permanent link">&para;</a></h4> <p>The size of the belief state may be too large: a state needs to encode <code>|P|</code> states information.</p> <p>A solution is to work on a solution for one physical state at once. Afterwards, this solution is applied to another physical state in the belief state. If this fails, the whole process is repeated with another solution for the first state. </p> <p>It detects failure fairly quickly. </p> <h3 id=with-observation>With observation<a class=headerlink href=#with-observation title="Permanent link">&para;</a></h3> <p>The problem definition is the same as for sensorless problems, except for the transition model. The transition model has three stages:</p> <ul> <li>Prediction: <code>b' = PREDICT(b, a)</code>. This is the same transition function for sensorless problems. </li> <li>Observation prediction (not used when executing): <code>POSSIBLE-PERCEPTS(b') = {o : o = PERCEPT(s) and s in b'}</code></li> <li>Update: <code>UPDATE(b', o) = {s : o = PERCEPT(s) and s in b'}</code>. Set of states in <code>b'</code> that could have produced the percept <code>o</code>. </li> </ul> <p>Unlike sensorless problems, the percepts are not null and depending on the percept received, the output belief state is different. Thus, the solution involves <strong>contingencies</strong>. </p> <p>Algorithms: - AND-OR graph search applied to the problem expressed in belief state space</p> <p>During execution, the agent needs to maintain its current belief state.</p> <h2 id=unknown-environments>Unknown environments<a class=headerlink href=#unknown-environments title="Permanent link">&para;</a></h2> <p><strong>Online search</strong>: interleaves computation and execution. It has to explore and then build heuristics. </p> <p><strong>Competitive ratio</strong>: ratio of path cost in online search over path cost when the space is already explored. </p> <p><strong>Safely explorable state space</strong>: where some goal state is reachable from every reachable state. No dead ends, reversible actions. </p> <p>The agent has access to: - <code>ACTIONS(s)</code>: all legal actions from s - Step cost function given the agent has visited the destination - Goal test - May have a heuristics <code>h(s)</code></p> <h3 id=online-depth-first-search-agent>Online Depth first search agent<a class=headerlink href=#online-depth-first-search-agent title="Permanent link">&para;</a></h3> <p>It applies DFS. </p> <p>The agent maintains: - Map <code>RESULT[s, a]</code> - Dict <code>UNBACKTRACKED[s]</code> to parent state - Dict <code>UNTRIED[s]</code> to untried actions (branches)</p> <p>If the goal is right next to the initial state, the agent may waste a lot of time exploring the other branch before backtracking and returning. To solve this problem, an <strong>iterative deepening DFS</strong> variant can be used, which is very effective for uniform trees. </p> <p>Because DFS needs to backtrack, the state space actions need to be reversible. </p> <h3 id=learning-real-time-a-agent-lrta>Learning real-time A<em> agent (LRTA</em>)<a class=headerlink href=#learning-real-time-a-agent-lrta title="Permanent link">&para;</a></h3> <p>It applies hill climbing. </p> <p>The agent maintains: - Map <code>RESULT[s, a]</code> - Current best estimate <code>H[s]</code>. Initially, this is <code>h(s)</code> by <strong>optimism under uncertainty</strong>. The value gets updated after the agent moves to another state. </p> <p>The <strong>action selection rule</strong> and the <strong>update rule</strong> can be customized. </p> <p>The agent can learn general rules, such as when <code>UP</code> action is executed the y coordinate is increased. This is covered in <a href=ch18-Example-Learning/README.md>chapter 18</a>.</p> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../ch3-classical-search/classical-search/ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Classical Search </div> </div> </a> <a href=../../ch5-adversarial-search/adversarial-search/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Adversarial search </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; RoundofThree </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "search.suggest", "search.highlight", "search.share"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../../../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script> <script src=../../../assets/javascripts/bundle.4ea5477f.min.js></script> <script src=../../../static/js/extra.js></script> <script src=https://cdnjs.loli.net/ajax/libs/pangu/3.3.0/pangu.min.js></script> <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>